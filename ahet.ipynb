{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hate Speech Classification\n",
    "#@darknurd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv', header=None, delimiter=\"\\t\", quoting=3)\n",
    "train_data.columns = [\"Sentiment\",\"Text\"]\n",
    "test_data = pd.read_csv('test_data.csv', header=None, delimiter=\"\\t\", quoting=3)\n",
    "test_data.columns = [\"Text\"]\n",
    "my_data = pd.read_csv('test1.csv', header=None, delimiter=\"\\t\", quoting=3)\n",
    "my_data.columns = [\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30459, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32541, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>And God said, Let there be light, and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>And God said, Let there be a vault between the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>And God said, Let the water under the sky be g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Then God said, Let the land produce vegetation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          0  In the beginning God created the heavens and t...\n",
       "1          1  And God said, Let there be light, and there wa...\n",
       "2          1  And God said, Let there be a vault between the...\n",
       "3          1  And God said, Let the water under the sky be g...\n",
       "4          1  Then God said, Let the land produce vegetation..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Then we had stupid trivia about San Francisco ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This means we beat out schools like MIT, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm off to harvard square bitches..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a big fan of Lakers, so I kind of have all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seattle sucks!!!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Then we had stupid trivia about San Francisco ...\n",
       "1  This means we beat out schools like MIT, which...\n",
       "2                i'm off to harvard square bitches..\n",
       "3  I'm a big fan of Lakers, so I kind of have all...\n",
       "4                                seattle sucks!!!..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you are my fuck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Text\n",
       "0  you are my fuck"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17719\n",
       "0    12740\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting how many labels do we have for each sentiment class.\n",
    "train_data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.041071604451886"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, let's calculate the average number of words per sentence. We could do the following using a list comprehension with the number of words per sentence.\n",
    "np.mean([len(s.split(\" \")) for s in train_data.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = 'english',\n",
    "                max_features = 85\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The method fit_transform does two functions: \\n    First, it fits the model and learns the vocabulary; \\n    second, it transforms our corpus data into feature vectors. \\n    The input to fit_transform should be a list of strings, \\n    so we concatenate train and test data as follows.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The method fit_transform does two functions: \n",
    "    First, it fits the model and learns the vocabulary; \n",
    "    second, it transforms our corpus data into feature vectors. \n",
    "    The input to fit_transform should be a list of strings, \n",
    "    so we concatenate train and test data as follows.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x85 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data_features = vectorizer.fit_transform(train_data.Text.tolist() + test_data.Text.tolist())\n",
    "corpus_data_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19)\t1\n",
      "  (0, 60)\t1\n",
      "  (0, 80)\t2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63000, 85)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (corpus_data_features[3])\n",
    "#converting to array\n",
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'aaa', u'airlin', u'amaz', u'angelina', u'awesom', u'beauti', u'becaus', u'boston', u'brokeback', u'citi', u'code', u'cool', u'cruis', u'd', u'da', u'francisco', u'friend', u'fuck', u'geico', u'good', u'got', u'great', u'ha', u'harri', u'harvard', u'hate', u'hi', u'hilton', u'honda', u'imposs', u'joli', u'just', u'know', u'laker', u'left', u'like', u'littl', u'london', u'look', u'love', u'm', u'macbook', u'make', u'miss', u'mission', u'mit', u'mountain', u'movi', u'need', u'new', u'oh', u'onli', u'pari', u'peopl', u'potter', u'purdu', u'realli', u'right', u'rock', u's', u'said', u'san', u'say', u'school', u'seattl', u'shanghai', u'stori', u'stuff', u'stupid', u'suck', u't', u'thi', u'thing', u'think', u'time', u'tom', u'toyota', u'ucla', u've', u'vinci', u'wa', u'want', u'way', u'whi', u'work']\n"
     ]
    }
   ],
   "source": [
    "# A look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901 aaa\n",
      "669 airlin\n",
      "882 amaz\n",
      "2551 angelina\n",
      "4845 awesom\n",
      "3065 beauti\n",
      "2489 becaus\n",
      "4050 boston\n",
      "2000 brokeback\n",
      "691 citi\n",
      "2003 code\n",
      "648 cool\n",
      "3459 cruis\n",
      "812 d\n",
      "2089 da\n",
      "3215 francisco\n",
      "669 friend\n",
      "672 fuck\n",
      "1934 geico\n",
      "1191 good\n",
      "881 got\n",
      "2085 great\n",
      "1118 ha\n",
      "2094 harri\n",
      "3401 harvard\n",
      "8023 hate\n",
      "1214 hi\n",
      "3671 hilton\n",
      "3665 honda\n",
      "1098 imposs\n",
      "2549 joli\n",
      "1398 just\n",
      "1309 know\n",
      "3775 laker\n",
      "670 left\n",
      "5528 like\n",
      "865 littl\n",
      "3779 london\n",
      "1190 look\n",
      "17806 love\n",
      "2534 m\n",
      "1841 macbook\n",
      "846 make\n",
      "1488 miss\n",
      "1102 mission\n",
      "2267 mit\n",
      "2167 mountain\n",
      "1224 movi\n",
      "1803 need\n",
      "772 new\n",
      "902 oh\n",
      "954 onli\n",
      "3682 pari\n",
      "1421 peopl\n",
      "2093 potter\n",
      "1787 purdu\n",
      "2993 realli\n",
      "855 right\n",
      "677 rock\n",
      "5708 s\n",
      "705 said\n",
      "3429 san\n",
      "973 say\n",
      "682 school\n",
      "3800 seattl\n",
      "2031 shanghai\n",
      "741 stori\n",
      "682 stuff\n",
      "5064 stupid\n",
      "7508 suck\n",
      "2221 t\n",
      "2487 thi\n",
      "903 thing\n",
      "1830 think\n",
      "1345 time\n",
      "3546 tom\n",
      "3138 toyota\n",
      "3329 ucla\n",
      "1051 ve\n",
      "2001 vinci\n",
      "5187 wa\n",
      "2452 want\n",
      "1365 way\n",
      "790 whi\n",
      "652 work\n"
     ]
    }
   ],
   "source": [
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(corpus_data_features_nd, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that corpus_data_features_nd contains all of our original train and test data, so we need to exclude\n",
    "# the unlabeled test entries\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    corpus_data_features_nd[0:len(train_data)], \n",
    "    train_data.Sentiment,\n",
    "    train_size=0.80, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Classifier\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99      2512\n",
      "          1       0.99      0.99      0.99      3580\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32541,)\n",
      "[14757, 14213, 27101, 368, 24886]\n",
      "0 tom cruise sucks.\n",
      "0 \" Angelina Jolie to play evil queen in'Beowulf'\"..\n",
      "0 stupid lakers!!!!!!!!!!!\n",
      "0 and i blame angelina jolie!\n",
      "0 actually the only thing that i really like about purdue is my apartment....\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=corpus_data_features_nd[0:len(train_data)], y=train_data.Sentiment)\n",
    "\n",
    "# get predictions\n",
    "test_pred = log_model.predict(corpus_data_features_nd[(len(train_data)):])\n",
    "\n",
    "print(test_pred.shape)\n",
    "\n",
    "# sample some of them\n",
    "import random\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "print spl\n",
    "# print text and labels\n",
    "for text, sentiment in zip(test_data.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
